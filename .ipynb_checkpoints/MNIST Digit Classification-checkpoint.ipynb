{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST text Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Load the data.........."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##  given a image which contains 1 to 9 digit we have to build a classifier \n",
    "##  to predict what no is written on the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17775101b8b9>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from sklearn.datasets import fetch_mldata \n",
    "# mnist = fetch_mldata('MNIST original', data_home=custom_data_home) \n",
    "# ## will fetch the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001BD16181F08>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001BD161878C8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001BD161874C8>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape , mnist.train.labels.shape\n",
    "## there are total 55000 flaten images and each images os of dimesion 28 x 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0] ## labels are hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape , mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "first_image = mnist.train.images[412]\n",
    "first_image = np.array(first_image , dtype = 'float')\n",
    "first_image = first_image.reshape((28 , 28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.163568    0.51946586  0.49945053 ... -0.4794342  -1.4662052\n",
      "   1.0500387 ]\n",
      " [-1.1206828  -0.23789042 -1.6842514  ...  0.35870042  0.6935915\n",
      "  -0.10781898]\n",
      " [ 0.817157   -0.8660302  -0.7321077  ...  1.1609097  -1.4961051\n",
      "  -0.08683012]\n",
      " ...\n",
      " [ 1.2753392   1.3234016  -0.98227155 ...  0.17960775 -1.5963558\n",
      "  -0.13026546]\n",
      " [ 0.6787441   0.63536936 -0.09550823 ...  0.95762986 -1.2170489\n",
      "   1.0597452 ]\n",
      " [ 0.0149205   0.25319952  1.1475748  ... -0.5938021  -0.13805698\n",
      "  -0.53822076]]\n"
     ]
    }
   ],
   "source": [
    "## random_normal\n",
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([784 , 256]).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Intialising weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) ) ,\n",
    "#     \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) , trainable = False) ,\n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_1 , n_hidden_2])) ,\n",
    "    \"out\" : tf.Variable(tf.random_normal([n_hidden_2 , n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_hidden_1])) , \n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_2])) , \n",
    "    \"out\" : tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x , weights , biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x , weights[\"h1\"]) , biases[\"h1\"])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1 , weights[\"h2\"]) , biases[\"h2\"])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2 , weights[\"out\"]) , biases[\"out\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Having identity activation function on all layers will lead to we learning linear decision boundary. \n",
    "In most problems that would lead to worse results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) finding the prediction and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "x = tf.placeholder(\"float\" , [None , n_input])\n",
    "y = tf.placeholder(tf.int32 , [None , n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 5, ..., 1, 7, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predicted output\n",
    "pred = forward_propagation(x , weights , biases)\n",
    "predictions = tf.argmax(pred , 1)\n",
    "predictions_eval = sess.run(predictions , feed_dict = {x : mnist.test.images})\n",
    "predictions_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## actual labels\n",
    "true_labels = tf.argmax(y , 1)\n",
    "labels = sess.run(true_labels , feed_dict = {y : mnist.test.labels})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correct prediction\n",
    "correct_predictions = tf.equal(predictions , true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 1, 5, ..., 1, 7, 1], dtype=int64),\n",
       " array([7, 2, 1, ..., 4, 5, 6], dtype=int64),\n",
       " array([False, False, False, ..., False, False, False]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## other way to run simultanously\n",
    "predictions_eval , labels , correct_pred = sess.run([predictions , true_labels , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "predictions_eval , labels , correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## how many we are getting correct\n",
    "correct_pred.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-b845cf64bfb6>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## cross entropy function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred , labels = y))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1926.4436"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cost , feed_dict = {x : mnist.train.images , y : mnist.train.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Running the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'Variable_6:0' shape=(784, 256) dtype=float32_ref>, <tf.Variable 'Variable_7:0' shape=(256, 256) dtype=float32_ref>, <tf.Variable 'Variable_8:0' shape=(256, 10) dtype=float32_ref>, <tf.Variable 'Variable_9:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_10:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot = True)\n",
    "\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_input , n_hidden_1]) ) ,\n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_1 , n_hidden_2])) ,\n",
    "    \"out\" : tf.Variable(tf.random_normal([n_hidden_2 , n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"h1\" : tf.Variable(tf.random_normal([n_hidden_1])) , \n",
    "    \"h2\" : tf.Variable(tf.random_normal([n_hidden_2])) , \n",
    "    \"out\" : tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "print(tf.trainable_variables())\n",
    "\n",
    "def forward_propagation(x , weights , biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x , weights[\"h1\"]) , biases[\"h1\"])\n",
    "    out_layer1 = tf.nn.relu(in_layer1)\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1 , weights[\"h2\"]) , biases[\"h2\"])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2 , weights[\"out\"]) , biases[\"out\"])\n",
    "    return output\n",
    "\n",
    "x = tf.placeholder(\"float\" , [None , n_input])\n",
    "y = tf.placeholder(tf.int32 , [None , n_classes])\n",
    "pred = forward_propagation(x , weights , biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred , labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate =  0.01)\n",
    "optimize = optimizer.minimize(cost)\n",
    "\n",
    "# minimize function ===>> finds the derivative(slope) values & chnage the values as per the learning rate\n",
    "# and the slopes once\n",
    "## if there is no variable which are trainable then this will give error \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1909.2466\n"
     ]
    }
   ],
   "source": [
    "c, _ = sess.run([cost,optimize], feed_dict = {x:mnist.train.images , y:mnist.train.labels})\n",
    "print(c)\n",
    "## every time we run it it will reduce the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) How does the optimizer work ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## first it will find which variables depends upon cost function and trainable = True\n",
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) running multiple iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287.4387\n",
      "993.3718\n",
      "823.77075\n",
      "630.5597\n",
      "498.0017\n",
      "422.03894\n",
      "324.6146\n",
      "243.89357\n",
      "206.42589\n",
      "199.79597\n",
      "201.87659\n",
      "197.06476\n",
      "181.93384\n",
      "163.32506\n",
      "147.52953\n",
      "134.63579\n",
      "122.8302\n",
      "112.28021\n",
      "104.36167\n",
      "99.75114\n",
      "97.71867\n",
      "96.584465\n",
      "94.556015\n",
      "90.68125\n",
      "85.33096\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c , _ = sess.run([cost , optimize] , feed_dict = {x : mnist.train.images , y : mnist.train.labels})\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8536"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred , 1)\n",
    "correct_labels = tf.argmax(y , 1)\n",
    "correct_predictions = tf.equal(predictions , correct_labels)\n",
    "predictions , correct_predictions = sess.run([predictions , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Batch gradient descent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "benefit of calling optimize in multiple batches :\n",
    "    it will be faster to reach the results\n",
    "    it will not reach better results irrespective of number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15119.32715946436\n",
      "4481.572406394545\n",
      "2514.48060637527\n",
      "1768.2681618012111\n",
      "1394.5199854758264\n",
      "1207.4041570759744\n",
      "987.7292077429545\n",
      "968.7826518540512\n",
      "860.862793349875\n",
      "687.7702338644447\n",
      "623.1387422478576\n",
      "500.2224838250191\n",
      "558.9333610557625\n",
      "444.09650698323\n",
      "477.2283421538824\n",
      "348.8355734739182\n",
      "316.13843687428215\n",
      "349.650730526278\n",
      "223.57271703032205\n",
      "217.3286543977516\n",
      "223.267177965108\n",
      "242.6425401395077\n",
      "186.42863172865722\n",
      "178.1000442850375\n",
      "154.8819588025214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9651"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples / batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x , batch_y = mnist.train.next_batch(batch_size)\n",
    "        c , _ = sess.run([cost ,optimize] , feed_dict = {x : batch_x , y : batch_y})\n",
    "        total_cost += c\n",
    "    print(total_cost)\n",
    "    \n",
    "predictions = tf.argmax(pred , 1)\n",
    "correct_labels = tf.argmax(y , 1)\n",
    "correct_predictions = tf.equal(predictions , correct_labels)\n",
    "predictions , correct_predictions = sess.run([predictions , correct_predictions] , feed_dict = {x : mnist.test.images , y : mnist.test.labels})\n",
    "\n",
    "correct_predictions.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
